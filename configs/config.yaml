bot:
  target_qq: 0           # 只回复这一个人的 QQ 号
  owner_qq: 0            # 管理员 QQ 号（你自己）
  my_name: ""            # 你的名字（用于 prompt）
  target_name: ""        # 对方的名字（用于 prompt）
  reply_delay_min_ms: 1000
  reply_delay_max_ms: 3000
  max_context_turns: 20
  session_timeout_min: 30

napcat:
  ws_url: "ws://127.0.0.1:3001"
  access_token: ""

gemini:
  api_key: ""                      # 优先从环境变量 GEMINI_API_KEY 读取
  chat_model: "gemini-2.5-pro"
  chat_models:                         # 高级优先，429 后降级
    - "gemini-3-pro-preview"           # 最强 RPD 1.5K
    - "gemini-2.5-pro"                 # 强   RPD 1.5K
    - "gemini-3-flash-preview"         # 快强 RPD 20
    - "gemini-2.5-flash"              # 快   RPD 20
    - "gemini-2.0-flash"              # 稳定 RPD 1.5K
    - "gemini-2.0-flash-exp"          # 实验 RPD 1.5K
    - "gemini-2.0-flash-lite"         # 轻量 RPD 1.5K
    - "gemini-2.5-flash-lite"         # 轻量 RPD 20
  embedding_model: "nomic-embed-text"    # 本地 Ollama 模型，不需要 API 额度
  ollama_url: "http://127.0.0.1:11434/api"
  temperature: 0.8
  max_output_tokens: 512
  rpm_limit: 10

rag:
  vectors_dir: "./data/vectors"
  top_k: 5
  min_similarity: 0.3

data:
  sessions_dir: "./data/sessions"
  persona_file: "./data/persona.json"
